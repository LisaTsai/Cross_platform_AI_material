{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 安裝PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: torchvision==0.4.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.4.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from torch==1.3.0) (1.17.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from torchvision==0.4.1) (6.1.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from torchvision==0.4.1) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch==1.3.0 torchvision==0.4.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 檢查PyTorch版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch 張量 (Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##匯入函式庫，numpy會是建立PyTorch張量的好幫手\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 用PyTorch生成張量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9169, 0.2939, 0.4052],\n",
       "        [0.6541, 0.9992, 0.1776]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "##兩種不同「查看維度屬性」的方法\n",
    "print(x.shape)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 複習：\n",
    "第零階張量-純量 <br /> \n",
    "第一階張量-向量<br /> \n",
    "第二階張量-矩陣<br /> \n",
    "第三階以上張量-張量<br /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8373, 0.2489, 0.9917, 0.7144, 0.5369],\n",
       "          [0.8290, 0.0578, 0.6364, 0.5963, 0.7052],\n",
       "          [0.7528, 0.3740, 0.6362, 0.4220, 0.7085],\n",
       "          [0.6688, 0.7499, 0.1913, 0.7012, 0.2168]],\n",
       "\n",
       "         [[0.3086, 0.0961, 0.0876, 0.6543, 0.7420],\n",
       "          [0.8526, 0.4401, 0.4274, 0.4589, 0.2411],\n",
       "          [0.8111, 0.3577, 0.3171, 0.4587, 0.8622],\n",
       "          [0.5898, 0.3102, 0.2402, 0.9610, 0.7940]],\n",
       "\n",
       "         [[0.6125, 0.0651, 0.0229, 0.3110, 0.7513],\n",
       "          [0.3354, 0.5185, 0.4780, 0.6855, 0.3955],\n",
       "          [0.7821, 0.9251, 0.4345, 0.1571, 0.0756],\n",
       "          [0.3716, 0.1517, 0.2056, 0.3312, 0.2461]]],\n",
       "\n",
       "\n",
       "        [[[0.9512, 0.3765, 0.8852, 0.4113, 0.2392],\n",
       "          [0.3525, 0.2704, 0.5454, 0.0528, 0.6720],\n",
       "          [0.5275, 0.7955, 0.9013, 0.5544, 0.1854],\n",
       "          [0.2510, 0.7392, 0.8731, 0.3520, 0.3498]],\n",
       "\n",
       "         [[0.9712, 0.4956, 0.5836, 0.1200, 0.6978],\n",
       "          [0.9885, 0.4170, 0.2495, 0.3541, 0.1924],\n",
       "          [0.0605, 0.9447, 0.1575, 0.0846, 0.8739],\n",
       "          [0.3458, 0.4432, 0.1303, 0.4944, 0.7338]],\n",
       "\n",
       "         [[0.9135, 0.2825, 0.0358, 0.7148, 0.0172],\n",
       "          [0.3523, 0.8761, 0.9782, 0.6360, 0.5356],\n",
       "          [0.0666, 0.4681, 0.8297, 0.2484, 0.0347],\n",
       "          [0.8893, 0.1673, 0.7473, 0.1412, 0.3405]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##試著生成多階張量吧！\n",
    "y=torch.rand(2,3,4,5)\n",
    "print(y.size())\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1416)\n",
      "torch.Size([])\n",
      "3.141592025756836\n"
     ]
    }
   ],
   "source": [
    "#純量\n",
    "scalar =torch.tensor(3.141592)\n",
    "print(scalar)\n",
    "print(scalar.size())\n",
    "print(scalar.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 基本數據類型\n",
    "\n",
    "32位元浮點數：torch.FloatTensor (default)<br /> \n",
    "64位元浮點數：torch.DoubleTensor<br /> \n",
    "16位元整數：torch.ShortTensor<br /> \n",
    "32位元整數：torch.IntTensor<br /> \n",
    "64位元整數：torch.LongTensor<br /> \n",
    "char：torch.int8<br /> \n",
    "btye：torch.uint8<br /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - long - \n",
      "tensor([3])\n",
      "\n",
      " - half - \n",
      "tensor([3.1406], dtype=torch.float16)\n",
      "\n",
      " - int - \n",
      "tensor([3], dtype=torch.int32)\n",
      "\n",
      " - float - \n",
      "tensor([3.1416])\n",
      "\n",
      " - short - \n",
      "tensor([3], dtype=torch.int16)\n",
      "\n",
      " - char - \n",
      "tensor([3], dtype=torch.int8)\n",
      "\n",
      " - byte - \n",
      "tensor([3], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([3.141592]) \n",
    "long_t=tensor.long()\n",
    "print(\" - long - \")\n",
    "print(long_t)\n",
    "half_t=tensor.half()\n",
    "print(\"\\n - half - \")\n",
    "print(half_t)\n",
    "int_t=tensor.int()\n",
    "print(\"\\n - int - \")\n",
    "print(int_t)\n",
    "float_t=tensor.float()\n",
    "print(\"\\n - float - \")\n",
    "print(float_t)\n",
    "short_t=tensor.short()\n",
    "print(\"\\n - short - \")\n",
    "print(short_t)\n",
    "char_t=tensor.char()\n",
    "print(\"\\n - char - \")\n",
    "print(char_t)\n",
    "byte_t=tensor.byte()\n",
    "print(\"\\n - byte - \")\n",
    "print(byte_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. tensor與Numpy中的ndarray互相轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3716, -0.6831],\n",
      "        [ 0.3051, -0.2912],\n",
      "        [-1.6451, -1.9067]])\n",
      "[[ 1.371623   -0.6830888 ]\n",
      " [ 0.30512834 -0.29123798]\n",
      " [-1.6451058  -1.9067299 ]]\n"
     ]
    }
   ],
   "source": [
    "##tensor to ndarray\n",
    "a = torch.randn((3, 2))\n",
    "print(a)\n",
    "numpy_a = a.numpy()\n",
    "print(numpy_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3716, -0.6831],\n",
       "        [ 0.3051, -0.2912],\n",
       "        [-1.6451, -1.9067]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ndarray to tensor\n",
    "torch_a = torch.from_numpy(numpy_a)\n",
    "torch_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意：\n",
    "tensor和ndarray共享記憶體，兩者之間的轉換很快，幾乎不會消耗什麼資源。<br />\n",
    "如果其中一個改變，另外一個也會隨之改變。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1771,  0.0649],\n",
      "        [-0.0519, -0.5028],\n",
      "        [-2.2636, -0.3999]])\n",
      "[[ 0.17706525  0.06488007]\n",
      " [-0.05190542 -0.50282264]\n",
      " [-2.2635949  -0.3998803 ]]\n"
     ]
    }
   ],
   "source": [
    "b = torch.randn((3, 2))\n",
    "torch_a.add_(b)\n",
    "#torch_a=torch_a+b\n",
    "print(torch_a)\n",
    "print(numpy_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 不同的張量初始化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7649, 0.7091, 0.8841, 0.8805],\n",
      "        [0.2049, 0.2878, 0.8374, 0.0596],\n",
      "        [0.7334, 0.0678, 0.8426, 0.1292],\n",
      "        [0.8830, 0.0414, 0.0194, 0.2495]])\n"
     ]
    }
   ],
   "source": [
    "## 隨機\n",
    "rand_t = torch.rand(4, 4)\n",
    "print(rand_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "## 全部填一\n",
    "ones_t = torch.ones(4, 4)\n",
    "print(ones_t)\n",
    "\n",
    "## 改變類型\n",
    "ones_t_new = torch.ones(4, 4,dtype=torch.long)\n",
    "print(ones_t_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.8363e+17, 2.0190e-19, 1.3563e-19, 4.5071e+16],\n",
      "        [1.4584e-19, 1.4584e-19, 1.4584e-19, 3.1432e-12],\n",
      "        [1.3589e-19, 1.3563e-19, 7.9717e-10, 5.8270e-10],\n",
      "        [5.8270e-10, 5.8270e-10, 4.9153e-14, 1.3494e+37]])\n"
     ]
    }
   ],
   "source": [
    "## 全部填零\n",
    "zeros_t=torch.zeros(4,4)\n",
    "#zeros_t=torch.empty(4,4)\n",
    "print(zeros_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "## 產生單位矩陣，若非方形矩陣，從左上角開始放一\n",
    "eye_t=torch.eye(4,4)\n",
    "print(eye_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 常用的張量運算處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5094, -1.8469, -0.7771],\n",
      "        [ 0.6504,  0.6050, -0.3706],\n",
      "        [-1.5832,  0.4724,  0.5322]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5094,  0.6504,  0.5322]) tensor([0, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "## 每行取最大值\n",
    "max_value, max_idx = torch.max(x, dim=1)\n",
    "print(max_value, max_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.1334,  0.8849, -0.5785])\n"
     ]
    }
   ],
   "source": [
    "## 每行求和\n",
    "sum_x = torch.sum(x, dim=1)\n",
    "print(sum_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2171,  2.6940, -0.4456],\n",
      "        [ 0.6608, -0.2053,  0.4663],\n",
      "        [-0.5552,  1.3075, -1.1836]])\n"
     ]
    }
   ],
   "source": [
    "## 加法1\n",
    "y = torch.randn(3, 3)\n",
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2171,  2.6940, -0.4456],\n",
      "        [ 0.6608, -0.2053,  0.4663],\n",
      "        [-0.5552,  1.3075, -1.1836]])\n"
     ]
    }
   ],
   "source": [
    "## 另一種加法\n",
    "x.add_(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3816,  4.3011, -1.1099],\n",
      "        [ 2.0299,  0.9813,  0.2349],\n",
      "        [-0.1365,  2.6820, -2.3487]])\n"
     ]
    }
   ],
   "source": [
    "## 加法3\n",
    "result = torch.empty(5,3)\n",
    "torch.add(x,y,out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5094, -1.8469, -0.7771],\n",
      "        [ 0.6504,  0.6050, -0.3706],\n",
      "        [-1.5832,  0.4724,  0.5322]])\n",
      "tensor([-1.8469,  0.6050,  0.4724])\n",
      "tensor([-1.5832,  0.4724,  0.5322])\n",
      "tensor([[-0.5094, -1.8469],\n",
      "        [ 0.6504,  0.6050]])\n"
     ]
    }
   ],
   "source": [
    "## 切片\n",
    "print(x)\n",
    "print(x[:,1])\n",
    "print(x[2,:])\n",
    "print(x[:2,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "tensor([[ 1.9814,  1.5767,  0.5532, -0.4946],\n",
      "        [-0.8551, -1.5518, -0.2142,  0.1846],\n",
      "        [-0.6233,  0.7324, -0.3944,  0.9039],\n",
      "        [-0.3809, -0.4961, -0.1506,  0.2058]])\n",
      "tensor([ 1.9814,  1.5767,  0.5532, -0.4946, -0.8551, -1.5518, -0.2142,  0.1846,\n",
      "        -0.6233,  0.7324, -0.3944,  0.9039, -0.3809, -0.4961, -0.1506,  0.2058])\n",
      "tensor([[ 1.9814,  1.5767,  0.5532, -0.4946, -0.8551, -1.5518, -0.2142,  0.1846],\n",
      "        [-0.6233,  0.7324, -0.3944,  0.9039, -0.3809, -0.4961, -0.1506,  0.2058]])\n",
      "tensor([[[[ 1.9814,  1.5767],\n",
      "          [ 0.5532, -0.4946]],\n",
      "\n",
      "         [[-0.8551, -1.5518],\n",
      "          [-0.2142,  0.1846]]],\n",
      "\n",
      "\n",
      "        [[[-0.6233,  0.7324],\n",
      "          [-0.3944,  0.9039]],\n",
      "\n",
      "         [[-0.3809, -0.4961],\n",
      "          [-0.1506,  0.2058]]]])\n"
     ]
    }
   ],
   "source": [
    "## 改變維度\n",
    "a = torch.randn(4,4)\n",
    "b = a.view(16)\n",
    "c = a.view(2,8)\n",
    "print(a.size(),b.size(),c.size())\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "#d = a.view(3,5)\n",
    "#print(d)\n",
    "e = a.view(2,2,2,2)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra - 改用cuda張量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x,device=device)\n",
    "    x = x.to(device)\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
